{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "_is_fork": false,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "_change_revision": 0,
    "language_info": {
      "version": "3.6.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "nbconvert_exporter": "python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "name": "python"
    },
    "colab": {
      "name": "(neural-network)80.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "1d09a305-ae97-cedc-ab9e-ffd895b00195",
        "_uuid": "ef25f721a19a0a59e78cc08ba5fc3a240564c710",
        "id": "_gP0WRriW8M4"
      },
      "source": [
        "# load modules\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "np.random.seed(1)\n",
        "# get data\n",
        "test  = pd.read_csv('/content/test.csv')\n",
        "train = pd.read_csv('/content/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "61fe6cdc-4d25-87e7-2ad2-105ffac58d1c",
        "_uuid": "70a7b89e4b0993822e01d9868a6cd20dad6faaa3",
        "id": "J_S8XkEdW8NA"
      },
      "source": [
        "print(train.shape)\n",
        "print(test.shape)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "ed57e3c7-4a4b-9eae-03b5-f769271b5e98",
        "_uuid": "9451f5a2ec6b6171fbaa09a6f88b5d3bbe9df849",
        "id": "NNpF086bW8NH"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(train[\"label\"])\n",
        "plt.title(\"Frequency Histogram of Numbers in Training Data\")\n",
        "plt.xlabel(\"Number Value\")\n",
        "plt.ylabel(\"Frequency\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "783f23f6-3bf8-9bfa-919c-4878314ad88e",
        "_uuid": "141c5fcff8f94e9a4a379fc1af5162a1d813fe56",
        "id": "yAt4a4QCW8NI"
      },
      "source": [
        "import math\n",
        "# plot the first 25 digits in the training set. \n",
        "f, ax = plt.subplots(5, 5)\n",
        "# plot some 4s as an example\n",
        "for i in range(1,26):\n",
        "    # Create a 1024x1024x3 array of 8 bit unsigned integers\n",
        "    data = train.iloc[i,1:785].values #this is the first number\n",
        "    nrows, ncols = 28, 28\n",
        "    grid = data.reshape((nrows, ncols))\n",
        "    n=math.ceil(i/5)-1\n",
        "    m=[0,1,2,3,4]*5\n",
        "    ax[m[i-1], n].imshow(grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d3441104-ec16-4309-04ec-40ac63f9b821",
        "_uuid": "d2052f0511cf57cbc6318d900c677b166ba0a63b",
        "id": "Z9TWySShW8NL"
      },
      "source": [
        "# PCA\n",
        "There are many features in this data resulting in high dimensionality. PCA is used to compress the features into a small but informative set of features before using the data in a machine learning model. Data is normalized before PCA is applied. This is so the scale of the data does not throw of the PCA, and so the 0's are represented meaningfully.  There is unequal variance in this data, and features with larger variance will influence the PCA more, creating bias. This is why the data is normalized. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "48e61f68-21e2-d101-d299-701433beab97",
        "_uuid": "e172a0b42717f7e71fe10626e1d354479960acff",
        "id": "eYjSXgPOW8NN"
      },
      "source": [
        "## normalize data ##\n",
        "label_train=train['label']\n",
        "train=train.drop('label', axis=1)\n",
        "\n",
        "#normalize data\n",
        "train = train / 255\n",
        "test = test / 255\n",
        "train['label'] = label_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "527791e7-3a05-09a2-970a-51dc3dfd3b5e",
        "_uuid": "04152a8265940d9577ece16b255f79747967fc6d",
        "id": "oPMyXLc_W8NQ"
      },
      "source": [
        "from sklearn import decomposition\n",
        "from sklearn import datasets\n",
        "\n",
        "## PCA decomposition\n",
        "pca = decomposition.PCA(n_components=200) #Finds first 200 PCs\n",
        "pca.fit(train.drop('label', axis=1))\n",
        "plt.plot(pca.explained_variance_ratio_)\n",
        "plt.ylabel('% of variance explained')\n",
        "#plot reaches asymptote at around 50, which is optimal number of PCs to use. \n",
        "\n",
        "## PCA decomposition with optimal number of PCs\n",
        "#decompose train data\n",
        "pca = decomposition.PCA(n_components=50) #use first 3 PCs (update to 100 later)\n",
        "pca.fit(train.drop('label', axis=1))\n",
        "PCtrain = pd.DataFrame(pca.transform(train.drop('label', axis=1)))\n",
        "PCtrain['label'] = train['label']\n",
        "\n",
        "#decompose test data\n",
        "#pca.fit(test)\n",
        "PCtest = pd.DataFrame(pca.transform(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "15f0b27d-a2e7-f836-f613-64c997145bb1",
        "_uuid": "0edf9e385a94ac60e473b635d1810d42b23faaba",
        "id": "nV0O04z4W8NT"
      },
      "source": [
        "This plot shows the separation of classes (digits) based on the first PCAs. Theoretically, these PCs should explain most of the variance in the data, enough to show separation in the groups of digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "2476c607-38f5-cd63-6169-063aef8626a8",
        "_uuid": "fa1a0ed49363d27bca9249b0a3da6cdd2290b7ca",
        "id": "CPEEt7HaW8NU"
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "#ax = fig.add_subplot(111)\n",
        "\n",
        "x =PCtrain[0]\n",
        "y =PCtrain[1]\n",
        "z =PCtrain[2]\n",
        "\n",
        "colors = [int(i % 9) for i in PCtrain['label']]\n",
        "ax.scatter(x, y, z, c=colors, marker='o', label=colors)\n",
        "\n",
        "ax.set_xlabel('PC1')\n",
        "ax.set_ylabel('PC2')\n",
        "ax.set_zlabel('PC3')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cab42f00-3379-e7e5-2163-f6944ad24378",
        "_uuid": "9a47bdfc54f24a64367c82a9696cec40e7ac2374",
        "id": "W0vwKSF2W8NV"
      },
      "source": [
        "#Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "89fbf7fd-06b8-dc26-1dd4-7025100fbb5b",
        "_uuid": "66c5cf1505a73fbdd056a924d0be6e1e030fb087",
        "id": "e9s489GAW8NW"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "y = PCtrain['label'][0:20000]\n",
        "X=PCtrain.drop('label', axis=1)[0:20000]\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                    hidden_layer_sizes=(3500,), random_state=1)\n",
        "clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "de8a400f-46e5-3d10-593c-0e03b3f15ed1",
        "_uuid": "15d08a842133f5bef919e70fbc00eb9ef689e12d",
        "id": "I1XegqwuW8NX"
      },
      "source": [
        "from sklearn import  metrics\n",
        "#accuracy and confusion matrix\n",
        "predicted = clf.predict(PCtrain.drop('label', axis=1)[20001:42000])\n",
        "expected = PCtrain['label'][20001:42000]\n",
        "\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "      % (clf, metrics.classification_report(expected, predicted)))\n",
        "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "9f081a14-7a1b-c6ae-c85d-31daa26d349f",
        "_uuid": "2abdb58b6697311df70f2400cdd8b89ffa012966",
        "id": "Gyd0ul3TW8NX"
      },
      "source": [
        "output = pd.DataFrame(clf.predict(PCtest), columns =['Label'])\n",
        "output.reset_index(inplace=True)\n",
        "output.rename(columns={'index': 'ImageId'}, inplace=True)\n",
        "output['ImageId']=output['ImageId']+1\n",
        "output.to_csv('output.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "85b71ffc-e756-5ebe-d094-6b928d6150d5",
        "_uuid": "50e278c6ea4584ed8b5d0992ea2100cfc76d654c",
        "id": "q8UlprE1W8NY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}